# Njuskalo Scraping Pipeline

A complete automated pipeline for scraping real estate data from Njuskalo.hr.

## ğŸš€ Quick Start

### Run Complete Pipeline
```bash
python pipeline.py
```

### Run Specific Steps
```bash
python pipeline.py --step 1  # Category scraper only
python pipeline.py --step 2  # HTML scraper only  
python pipeline.py --step 3  # Phone fetcher only
python pipeline.py --step 4  # Parser only
```

### Skip Existing Data
```bash
python pipeline.py --skip-existing
```

### Windows Batch File
```bash
run_pipeline.bat
```

## ğŸ“‹ Pipeline Steps

### Step 1: Category Tree Scraper
- **Script**: `njuskalo_category_tree_scraper.py`
- **Purpose**: Scrape category tree and collect all property listing URLs
- **Output**: Category data and URL lists

### Step 2: HTML Page Scraper  
- **Script**: `scrape_leaf_entries.py`
- **Purpose**: Download individual property listing HTML pages
- **Output**: `backend/website/` directory with HTML files
- **Features**: 
  - Checkpointing and resume capability
  - Proxy rotation and session management
  - Block detection and retry logic

### Step 3: Phone Number Fetcher
- **Script**: `fetch_phones_from_api.py` 
- **Purpose**: Extract phone numbers via Njuskalo API
- **Output**: `backend/phoneDB/phones.db` SQLite database
- **Features**:
  - Skip already-processed ads
  - Bearer token auto-refresh
  - High-throughput async processing (50 req/sec)

### Step 4: Ultrafast Parser
- **Script**: `parser_ultrafast.py`
- **Purpose**: Parse HTML files to structured JSON data
- **Output**: `backend/json/` directory with parsed data
- **Features**:
  - Memory-cached phone number lookups
  - Multi-core processing with all CPU cores
  - 3-5x faster than standard parser

## ğŸ“Š Output Structure

```
backend/
â”œâ”€â”€ website/           # HTML files from Step 2
â”œâ”€â”€ phoneDB/           # Phone database from Step 3
â”‚   â”œâ”€â”€ phones.db      # SQLite database
â”‚   â””â”€â”€ phones.log     # Phone fetcher logs
â”œâ”€â”€ json/              # Parsed JSON from Step 4
â””â”€â”€ logs/              # Parser logs
```

## ğŸ”§ Configuration

### Phone Fetcher Settings
- `RESCRAPE_NULL_PHONES = False` - Set to `True` to re-scrape ads with no phone numbers
- `BATCH_SIZE = 50` - Number of concurrent API requests

### Parser Settings  
- `BATCH_SIZE = 200` - Files per processing batch
- `MAX_WORKERS = cpu_count()` - Uses all CPU cores

## ğŸ“ Logging

- **Pipeline log**: `pipeline.log` - Overall pipeline execution
- **Phone log**: `backend/phoneDB/phones.log` - Phone fetching details
- **Parser logs**: `backend/logs/` - Individual parsing logs

## âš¡ Performance

Expected throughput:
- **Phone Fetcher**: ~50 requests/second
- **Parser**: 3-5x faster than standard parser
- **Complete pipeline**: Depends on data size and network speed

## ğŸ› ï¸ Troubleshooting

### Resume from Failure
The pipeline supports resuming from any step. Each step checks for existing output and can skip completed work.

### Individual Step Execution
If a step fails, you can re-run just that step:
```bash
python pipeline.py --step 3  # Re-run phone fetcher only
```

### Skip Existing Data
Use `--skip-existing` to avoid re-processing existing data:
```bash
python pipeline.py --skip-existing
```

## ğŸ“ Required Files

Make sure these files exist in your project directory:
- `njuskalo_category_tree_scraper.py`
- `scrape_leaf_entries.py` 
- `fetch_phones_from_api.py`
- `parser_ultrafast.py`
- `bearer_token_finder.py` (required by phone fetcher)

## ğŸš¨ Notes

- The `backend/` folder is excluded from Git (see `.gitignore`)
- Phone fetching requires valid bearer tokens (handled automatically)
- Parser uses memory caching for maximum speed
- All steps include comprehensive error handling and logging
